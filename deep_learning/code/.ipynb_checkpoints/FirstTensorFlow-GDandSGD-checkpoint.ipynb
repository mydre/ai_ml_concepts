{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_y = pickle.load(open(\"../datasets/notMNIST/all_image_array_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_y_test = pickle.load(open(\"../datasets/notMNIST/all_image_array_test.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y[1:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y[1:10,0][:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(X_y[:,0][:,None])\n",
    "y = np.asarray(enc.transform(X_y[:,0][:,None]).toarray())\n",
    "y_test = np.asarray(enc.transform(X_y_test[:,0][:,None]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10009, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_y[:,1:785]\n",
    "X_y_test = X_y_test[:,1:785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"SoftmaxCrossEntropyWithLogits:0\", shape=(6706,), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X_train_tf = tf.cast(tf.constant(X_train), tf.float32)\n",
    "    y_train_tf = tf.cast(tf.constant(y_train), tf.float32)\n",
    "    \n",
    "    X_valid_tf = tf.cast(tf.constant(X_valid), tf.float32)\n",
    "    \n",
    "    X_test_tf = tf.cast(tf.constant(X_y_test), tf.float32)\n",
    "\n",
    "    norm_dist_weights = tf.truncated_normal([X.shape[1], y.shape[1]])\n",
    "\n",
    "    norm_dist_weights_tf = tf.Variable(norm_dist_weights)\n",
    "\n",
    "    norm_dist_weights\n",
    "\n",
    "    y.shape[1]\n",
    "\n",
    "    biases_tf = tf.Variable(tf.zeros([y.shape[1]]))\n",
    "\n",
    "    X_train.shape\n",
    "\n",
    "    logits = tf.matmul(X_train_tf, norm_dist_weights_tf) + biases_tf\n",
    "    tf_loss_alldata_perclass = tf.nn.softmax_cross_entropy_with_logits(logits, y_train_tf)\n",
    "    print (tf_loss_alldata_perclass)\n",
    "    loss = tf.reduce_mean(tf_loss_alldata_perclass)\n",
    "    print(loss)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    y_train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    y_valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(X_valid_tf,norm_dist_weights_tf) + biases_tf\n",
    "    )\n",
    "\n",
    "    y_test_prediction = tf.nn.softmax(\n",
    "    tf.matmul(X_test_tf,norm_dist_weights_tf) + biases_tf\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast:0' shape=(6706, 784) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truncated_normal:0' shape=(784, 10) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dist_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(6706, 10) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast_1:0' shape=(6706, 10) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "loss at step 0: 8156.0527\n",
      "Training accuracy: 12.29%\n",
      "Validation accuracy: 36.44%\n",
      "Testing accuracy: 39.48%\n",
      "loss at step 100: 80781.0859\n",
      "Training accuracy: 68.36%\n",
      "Validation accuracy: 64.68%\n",
      "Testing accuracy: 71.15%\n",
      "loss at step 200: 46139.1289\n",
      "Training accuracy: 74.23%\n",
      "Validation accuracy: 72.03%\n",
      "Testing accuracy: 79.09%\n",
      "loss at step 300: 42667.6758\n",
      "Training accuracy: 76.35%\n",
      "Validation accuracy: 73.40%\n",
      "Testing accuracy: 80.86%\n",
      "loss at step 400: 38270.7500\n",
      "Training accuracy: 78.41%\n",
      "Validation accuracy: 74.24%\n",
      "Testing accuracy: 81.69%\n",
      "loss at step 500: 31043.1953\n",
      "Training accuracy: 79.66%\n",
      "Validation accuracy: 75.67%\n",
      "Testing accuracy: 82.76%\n",
      "loss at step 600: 36743.2930\n",
      "Training accuracy: 78.17%\n",
      "Validation accuracy: 73.94%\n",
      "Testing accuracy: 81.65%\n",
      "loss at step 700: 41758.1211\n",
      "Training accuracy: 76.87%\n",
      "Validation accuracy: 74.58%\n",
      "Testing accuracy: 81.48%\n",
      "loss at step 800: 31560.0781\n",
      "Training accuracy: 78.71%\n",
      "Validation accuracy: 73.94%\n",
      "Testing accuracy: 81.41%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, label):\n",
    "    return(100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(label, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print (\"Initialized\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        _, curr_loss, predictions = session.run([optimizer, loss, y_train_prediction])\n",
    "        # below code is required for display purpose only\n",
    "        \n",
    "        if(step % 100 == 0):\n",
    "            print('loss at step %d: %.4f' % (step, curr_loss))\n",
    "            print('Training accuracy: %.2f%%' % accuracy(predictions, y_train))\n",
    "            print('Validation accuracy: %.2f%%' % accuracy(y_valid_prediction.eval(), y_valid))\n",
    "            print('Testing accuracy: %.2f%%' % accuracy(y_test_prediction.eval(), y_test))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_prediction = tf.nn.softmax(logits)\n",
    "#valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases) \n",
    "#test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_scd = tf.Graph()\n",
    "with graph_scd.as_default():\n",
    "    tf_X_train_scd = tf.placeholder(dtype=tf.float32, shape=X_train.shape)\n",
    "    tf_y_train_scd = tf.placeholder(dtype=tf.float32, shape = y_train.shape)\n",
    "    \n",
    "    tf_weights_scd = tf.Variable(tf.truncated_normal(shape=[X_train.shape[1], y_train.shape[1]], dtype=tf.float32))\n",
    "    tf_biases_scd = tf.Variable(tf.zeros(shape=y_train.shape[1]))\n",
    "    \n",
    "    logits = tf.matmul(a=tf_X_train_scd, b=tf_weights_scd) + tf_biases_scd\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_y_train_scd))    \n",
    "    tf_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n",
    "    \n",
    "    tf_y_pred_scd = tf.nn.softmax(logits)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "index = np.random.randint(low=0, high = 6706, size=batch_size)\n",
    "batch_X_train = X_train[index,:]\n",
    "batch_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(6706, 784), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-77a3483ff07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_X_train_scd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_y_train_scd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_y_pred_scd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    863\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m--> 865\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(6706, 784), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "num_steps = 301\n",
    "batch_size = 100\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for i in range(num_steps):\n",
    "        index = np.random.randint(low=0, high = 6706, size=batch_size)\n",
    "        batch_X_train = X_train[index,:]\n",
    "        batch_y_train = y_train[index,:]\n",
    "        feed_dict = {tf_X_train_scd:batch_X_train, tf_y_train_scd:batch_y_train}\n",
    "        _, l, predictions = session.run([optimizer, loss, tf_y_pred_scd], feed_dict = feed_dict)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
