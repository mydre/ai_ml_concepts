{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_y = pickle.load(open(\"../datasets/notMNIST/all_image_array_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_y_test = pickle.load(open(\"../datasets/notMNIST/all_image_array_test.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_y[1:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_y[1:10,0][:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(X_y[:,0][:,None])\n",
    "y = np.asarray(enc.transform(X_y[:,0][:,None]).toarray())\n",
    "y_test = np.asarray(enc.transform(X_y_test[:,0][:,None]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_y[:,1:785]\n",
    "X_y_test = X_y_test[:,1:785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X_train_tf = tf.cast(tf.constant(X_train), tf.float32)\n",
    "    y_train_tf = tf.cast(tf.constant(y_train), tf.float32)\n",
    "    \n",
    "    X_valid_tf = tf.cast(tf.constant(X_valid), tf.float32)\n",
    "    \n",
    "    X_test_tf = tf.cast(tf.constant(X_y_test), tf.float32)\n",
    "\n",
    "    norm_dist_weights = tf.truncated_normal([X.shape[1], y.shape[1]])\n",
    "\n",
    "    norm_dist_weights_tf = tf.Variable(norm_dist_weights)\n",
    "\n",
    "    norm_dist_weights\n",
    "\n",
    "    y.shape[1]\n",
    "\n",
    "    biases_tf = tf.Variable(tf.zeros([y.shape[1]]))\n",
    "\n",
    "    X_train.shape\n",
    "\n",
    "    logits = tf.matmul(X_train_tf, norm_dist_weights_tf) + biases_tf\n",
    "    tf_loss_alldata_perclass = tf.nn.softmax_cross_entropy_with_logits(logits, y_train_tf)\n",
    "    print (tf_loss_alldata_perclass)\n",
    "    loss = tf.reduce_mean(tf_loss_alldata_perclass)\n",
    "    print(loss)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    y_train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    y_valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(X_valid_tf,norm_dist_weights_tf) + biases_tf\n",
    "    )\n",
    "\n",
    "    y_test_prediction = tf.nn.softmax(\n",
    "    tf.matmul(X_test_tf,norm_dist_weights_tf) + biases_tf\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_dist_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, label):\n",
    "    return(100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(label, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print (\"Initialized\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        _, curr_loss, predictions = session.run([optimizer, loss, y_train_prediction])\n",
    "        # below code is required for display purpose only\n",
    "        \n",
    "        if(step % 100 == 0):\n",
    "            print('loss at step %d: %.4f' % (step, curr_loss))\n",
    "            print('Training accuracy: %.2f%%' % accuracy(predictions, y_train))\n",
    "            print('Validation accuracy: %.2f%%' % accuracy(y_valid_prediction.eval(), y_valid))\n",
    "            print('Testing accuracy: %.2f%%' % accuracy(y_test_prediction.eval(), y_test))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_prediction = tf.nn.softmax(logits)\n",
    "#valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases) \n",
    "#test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_scd = tf.Graph()\n",
    "with graph_scd.as_default():\n",
    "    tf_X_train_scd = tf.placeholder(dtype=tf.float32, shape=X_train.shape)\n",
    "    tf_y_train_scd = tf.placeholder(dtype=tf.float32, shape = y_train.shape)\n",
    "    \n",
    "    tf_weights_scd = tf.Variable(tf.truncated_normal(shape=[X_train.shape[1], y_train.shape[1]], dtype=tf.float32))\n",
    "    tf_biases_scd = tf.Variable(tf.zeros(shape=y_train.shape[1]))\n",
    "    \n",
    "    logits = tf.matmul(a=tf_X_train_scd, b=tf_weights_scd) + tf_biases_scd\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_y_train_scd))    \n",
    "    tf_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
