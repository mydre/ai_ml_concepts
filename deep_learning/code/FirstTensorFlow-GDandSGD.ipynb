{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_y = pickle.load(open(\"all_image_array_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_y_test = pickle.load(open(\"all_image_array_test.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y[1:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y[1:10,0][:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(X_y[:,0][:,None])\n",
    "y = np.asarray(enc.transform(X_y[:,0][:,None]).toarray())\n",
    "y_test = np.asarray(enc.transform(X_y_test[:,0][:,None]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10010, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10009, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_y[:,1:785]\n",
    "X_y_test = X_y_test[:,1:785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"SoftmaxCrossEntropyWithLogits:0\", shape=(6706,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X_train_tf = tf.cast(tf.constant(X_train), tf.float32)\n",
    "    y_train_tf = tf.cast(tf.constant(y_train), tf.float32)\n",
    "    \n",
    "    X_valid_tf = tf.cast(tf.constant(X_valid), tf.float32)\n",
    "    \n",
    "    X_test_tf = tf.cast(tf.constant(X_y_test), tf.float32)\n",
    "\n",
    "    norm_dist_weights = tf.truncated_normal([X.shape[1], y.shape[1]])\n",
    "\n",
    "    norm_dist_weights_tf = tf.Variable(norm_dist_weights)\n",
    "\n",
    "    norm_dist_weights\n",
    "\n",
    "    y.shape[1]\n",
    "\n",
    "    biases_tf = tf.Variable(tf.zeros([y.shape[1]]))\n",
    "\n",
    "    X_train.shape\n",
    "\n",
    "    logits = tf.matmul(X_train_tf, norm_dist_weights_tf) + biases_tf\n",
    "    tf_loss_alldata_perclass = tf.nn.softmax_cross_entropy_with_logits(logits, y_train_tf)\n",
    "    print (tf_loss_alldata_perclass)\n",
    "    loss = tf.reduce_mean(tf_loss_alldata_perclass)\n",
    "    print(loss)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    y_train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    y_valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(X_valid_tf,norm_dist_weights_tf) + biases_tf\n",
    "    )\n",
    "\n",
    "    y_test_prediction = tf.nn.softmax(\n",
    "    tf.matmul(X_test_tf,norm_dist_weights_tf) + biases_tf\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast:0' shape=(6706, 784) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truncated_normal:0' shape=(784, 10) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dist_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(6706, 10) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast_1:0' shape=(6706, 10) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "loss at step 0: 9463.0752\n",
      "Training accuracy: 10.50%\n",
      "Validation accuracy: 28.60%\n",
      "Testing accuracy: 31.20%\n",
      "loss at step 100: 62310.1523\n",
      "Training accuracy: 73.26%\n",
      "Validation accuracy: 72.06%\n",
      "Testing accuracy: 79.67%\n",
      "loss at step 200: 34646.9609\n",
      "Training accuracy: 78.47%\n",
      "Validation accuracy: 73.61%\n",
      "Testing accuracy: 81.14%\n",
      "loss at step 300: 54471.3594\n",
      "Training accuracy: 70.76%\n",
      "Validation accuracy: 68.77%\n",
      "Testing accuracy: 75.40%\n",
      "loss at step 400: 79131.2500\n",
      "Training accuracy: 60.50%\n",
      "Validation accuracy: 67.55%\n",
      "Testing accuracy: 74.12%\n",
      "loss at step 500: 47812.9531\n",
      "Training accuracy: 73.11%\n",
      "Validation accuracy: 70.97%\n",
      "Testing accuracy: 78.13%\n",
      "loss at step 600: 33268.1055\n",
      "Training accuracy: 79.51%\n",
      "Validation accuracy: 74.18%\n",
      "Testing accuracy: 81.23%\n",
      "loss at step 700: 46324.4922\n",
      "Training accuracy: 74.80%\n",
      "Validation accuracy: 72.15%\n",
      "Testing accuracy: 80.00%\n",
      "loss at step 800: 42465.0078\n",
      "Training accuracy: 76.96%\n",
      "Validation accuracy: 72.03%\n",
      "Testing accuracy: 78.70%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, label):\n",
    "    return(100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(label, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print (\"Initialized\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        _, curr_loss, predictions = session.run([optimizer, loss, y_train_prediction])\n",
    "        # below code is required for display purpose only\n",
    "        \n",
    "        if(step % 100 == 0):\n",
    "            print('loss at step %d: %.4f' % (step, curr_loss))\n",
    "            print('Training accuracy: %.2f%%' % accuracy(predictions, y_train))\n",
    "            print('Validation accuracy: %.2f%%' % accuracy(y_valid_prediction.eval(), y_valid))\n",
    "            print('Testing accuracy: %.2f%%' % accuracy(y_test_prediction.eval(), y_test))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_prediction = tf.nn.softmax(logits)\n",
    "#valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases) \n",
    "#test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_scd = tf.Graph()\n",
    "with graph_scd.as_default():\n",
    "    tf_X_train_scd = tf.placeholder(dtype=tf.float32, shape=X_train.shape)\n",
    "    tf_y_train_scd = tf.placeholder(dtype=tf.float32, shape = y_train.shape)\n",
    "    \n",
    "    tf_weights_scd = tf.Variable(tf.truncated_normal(shape=[X_train.shape[1], y_train.shape[1]], dtype=tf.float32))\n",
    "    tf_biases_scd = tf.Variable(tf.zeros(shape=y_train.shape[1]))\n",
    "    \n",
    "    logits = tf.matmul(a=tf_X_train_scd, b=tf_weights_scd) + tf_biases_scd\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_y_train_scd))    \n",
    "    tf_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
